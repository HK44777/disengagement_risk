{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbR9BW+6FW7pUq8z4slUkW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK1aRbkRP5L4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Mz8Ckox6j_Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/Dataset - Dataset.csv\")"
      ],
      "metadata": {
        "id": "6dObA99BkA_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "id": "ywuJeTm6kD4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ydata-profiling\n"
      ],
      "metadata": {
        "id": "B5zNly-8oZ-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(\n",
        "    df,\n",
        "    title=\"EDA Report\",\n",
        "    explorative=True\n",
        ")\n",
        "profile.to_file(\"eda_report.html\")"
      ],
      "metadata": {
        "id": "rQcshGcHoknL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"student_id\",axis=1)"
      ],
      "metadata": {
        "id": "0K-UM3E7o0oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "bfDT2tSCwaBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "ppXnkJNQwdAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Wz6weVF6whZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
        "\n",
        "unique_cats = {\n",
        "    col: df[col].unique()\n",
        "    for col in cat_cols\n",
        "}\n",
        "unique_cats\n"
      ],
      "metadata": {
        "id": "0avXii5HwiNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_maps = {\n",
        "    \"gender\": {\n",
        "        \"Male\": \"M\",\n",
        "        \"Female\": \"F\",\n",
        "        \"FEMALE\": \"F\",\n",
        "        \"Other\":\"O\"\n",
        "    },\n",
        "    \"scholarship\": {\n",
        "        \"Yes\": \"Y\",\n",
        "        \"No\": \"N\",\n",
        "        \"Nope\": \"N\"\n",
        "    },\n",
        "    \"extra_curricular\": {\n",
        "        \"Yes\": \"Y\",\n",
        "        \"No\": \"N\",\n",
        "        \"Nope\": \"N\",\n",
        "        \"-\":np.nan\n",
        "    },\n",
        "    \"sports_participation\": {\n",
        "        \"Yes\": \"Y\",\n",
        "        \"No\": \"N\",\n",
        "        \"Nope\": \"N\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "A2xdAYHu0fod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col, mapping in value_maps.items():\n",
        "    df[col] = df[col].replace(mapping)"
      ],
      "metadata": {
        "id": "xr6paKPd1__g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(15)"
      ],
      "metadata": {
        "id": "Jtfg0MDA2AnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FuCyCB0Q2By4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"parental_education\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "jv2trB6e2a71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"dropout\"].value_counts()"
      ],
      "metadata": {
        "id": "T_hku6WH3DtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(15)"
      ],
      "metadata": {
        "id": "p8M9B4X-3Xeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(columns=[\"dropout\"])   # features\n",
        "y = df[\"dropout\"]                  # label\n"
      ],
      "metadata": {
        "id": "ATunO4qX3hxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "rmylyCFaH8XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "O0uDphrVIM8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_null_rows = df[df.isna().all(axis=1)]\n",
        "full_null_rows"
      ],
      "metadata": {
        "id": "af15pefjIO-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = int(0.5 * df.shape[1])   # 50% non-null required\n",
        "\n",
        "rows_to_drop = df.isna().sum(axis=1) > (df.shape[1] - threshold)\n",
        "\n",
        "rows_to_drop.any()"
      ],
      "metadata": {
        "id": "lh-UQGW4Inlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "BMZPKF2dMaQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"family_income\"] >= 0]\n"
      ],
      "metadata": {
        "id": "gjyV64iCNf8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "wa7Xek7EP8dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "IM0wiUAAP9WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_train.select_dtypes(include=\"number\").columns\n",
        "num_cols"
      ],
      "metadata": {
        "id": "cLdvYFQuQKcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "for col in num_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.histplot(X_train[col], kde=True)\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3toLLIRyUJL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols:\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "UO9lmKsCUWhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "48MfRG_RUoUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Custom Transformer for Value Mapping\n",
        "class CustomValueMapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, mapping_dict):\n",
        "        self.mapping_dict = mapping_dict\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_copy = X.copy()\n",
        "        for col, mapping in self.mapping_dict.items():\n",
        "            if col in X_copy.columns:\n",
        "                X_copy[col] = X_copy[col].replace(mapping)\n",
        "        return X_copy\n",
        "\n",
        "\n",
        "median_cols = ['attendance_rate', 'family_income']\n",
        "mean_cols = ['age', 'cgpa', 'past_failures',\n",
        "       'study_hours_per_week', 'assignments_submitted', 'projects_completed',\n",
        "       'total_activities']\n",
        "cat_cols = ['department', 'gender','scholarship','extra_curricular','sports_participation']\n",
        "\n",
        "# Pipeline 1: Numerical (Outliers) -> Median + Standard Scaling\n",
        "median_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline 2: Numerical (Normal) -> Mean + Standard Scaling\n",
        "mean_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline 3: Categorical -> Custom Mapping + Most Frequent + OneHot (Drop First)\n",
        "cat_pipeline = Pipeline([\n",
        "    ('mapper', CustomValueMapper(value_maps)), # Add custom mapper here\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    # Note: handle_unknown='ignore' usually conflicts with drop='first' in older sklearn versions.\n",
        "    # If error occurs, remove handle_unknown.\n",
        "])\n",
        "\n",
        "# Master Preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num_median', median_pipeline, median_cols),\n",
        "        ('num_mean', mean_pipeline, mean_cols),\n",
        "        ('cat', cat_pipeline, cat_cols)\n",
        "    ],\n",
        "    remainder='drop' # Drop any columns not mentioned above\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 3. Define Models to Spot Check\n",
        "# ==========================================\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(max_iter=1000,class_weight='balanced')),\n",
        "    ('Decision Tree', DecisionTreeClassifier(class_weight='balanced')),\n",
        "    ('Random Forest', RandomForestClassifier(class_weight='balanced')),\n",
        "    ('SVM', SVC(class_weight='balanced')),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
        "    ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss',scale_pos_weight=4))\n",
        "]\n"
      ],
      "metadata": {
        "id": "bX-5TQJDYYSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "scoring_metrics = ['accuracy', 'f1', 'precision', 'recall']\n",
        "\n",
        "print(\"Running Cross-Validation on Training Set...\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    # Create a pipeline for each model so preprocessing happens INSIDE the fold\n",
        "    model_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Run Stratified K-Fold CV\n",
        "    cv_results = cross_validate(\n",
        "        model_pipeline,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring=scoring_metrics,\n",
        "        n_jobs=-1 # Use all processors\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    results_list.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': cv_results['test_accuracy'].mean(),\n",
        "        'F1 Score': cv_results['test_f1'].mean(),\n",
        "        'Precision': cv_results['test_precision'].mean(),\n",
        "        'Recall': cv_results['test_recall'].mean()\n",
        "    })\n",
        "\n",
        "# ==========================================\n",
        "# 5. Display Final Leaderboard\n",
        "# ==========================================\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df = results_df.sort_values(by='F1 Score', ascending=False)\n",
        "\n",
        "print(results_df.round(4))"
      ],
      "metadata": {
        "id": "G5mMYQA-btqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# --- Logistic Regression Grid ---\n",
        "lr_params = {\n",
        "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'model__penalty': ['l2'],\n",
        "    'model__solver': ['lbfgs']\n",
        "}\n",
        "\n",
        "def print_best_cv_results(grid_search, model_name):\n",
        "    print(f\"\\n--- {model_name} TUNING RESULTS ---\")\n",
        "    print(f\"Best Params: {grid_search.best_params_}\")\n",
        "\n",
        "    # Get the index of the best model\n",
        "    best_idx = grid_search.best_index_\n",
        "\n",
        "    # Extract the mean scores for that specific winning model\n",
        "    mean_f1 = grid_search.cv_results_['mean_test_f1'][best_idx]\n",
        "    mean_prec = grid_search.cv_results_['mean_test_precision'][best_idx]\n",
        "    mean_rec = grid_search.cv_results_['mean_test_recall'][best_idx]\n",
        "\n",
        "    print(f\"Best CV F1 Score:  {mean_f1:.4f}\")\n",
        "    print(f\"Corresponding CV Precision: {mean_prec:.4f}\")\n",
        "    print(f\"Corresponding CV Recall:    {mean_rec:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. Run Tuning for Logistic Regression\n",
        "# ==========================================\n",
        "print(\"Tuning Logistic Regression...\")\n",
        "\n",
        "lr_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# Scoring: We track all 3, but 'refit' tells it to choose the winner based on 'f1'\n",
        "grid_lr = GridSearchCV(\n",
        "    lr_pipeline,\n",
        "    lr_params,\n",
        "    cv=5,\n",
        "    scoring=['f1', 'precision', 'recall'],\n",
        "    refit='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "# Print CV Results\n",
        "print_best_cv_results(grid_lr, \"Logistic Regression\")\n",
        "\n",
        "# Final Test Set Prediction\n",
        "print(\"\\n...Evaluating Logistic Regression on Test Set...\")\n",
        "y_pred_lr = grid_lr.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VQdy-zYsl5vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "print(\"Tuning XGBoost...\")\n",
        "\n",
        "\n",
        "xgb_params = {\n",
        "    'model__n_estimators': [100, 200],\n",
        "    'model__max_depth': [3, 5, 7],\n",
        "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'model__scale_pos_weight': [3, 3 * 1.5]\n",
        "}\n",
        "\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
        "])\n",
        "\n",
        "grid_xgb = GridSearchCV(\n",
        "    xgb_pipeline,\n",
        "    xgb_params,\n",
        "    cv=5,\n",
        "    scoring=['f1', 'precision', 'recall'],\n",
        "    refit='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Print CV Results\n",
        "print_best_cv_results(grid_xgb, \"XGBoost\")\n",
        "\n",
        "# Final Test Set Prediction\n",
        "print(\"\\n...Evaluating XGBoost on Test Set...\")\n",
        "y_pred_xgb = grid_xgb.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "id": "im8l8PojrVRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(grid_xgb, 'risk_model.pkl')"
      ],
      "metadata": {
        "id": "GLCN2ssPtHYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('risk_model.pkl')"
      ],
      "metadata": {
        "id": "gaX-bpIshrAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-EbaayLiN5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}